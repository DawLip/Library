{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: pandas in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: matplotlib in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: pydot in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (3.0.4)\n",
      "Requirement already satisfied: graphviz in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (0.20.3)\n",
      "Requirement already satisfied: keras_tuner in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (1.4.7)\n",
      "Collecting faker\n",
      "  Downloading Faker-33.3.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (5.29.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: kt-legacy in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/david/Workspace/c_project/.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Downloading Faker-33.3.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faker\n",
      "Successfully installed faker-33.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pandas scikit-learn matplotlib seaborn pydot graphviz keras_tuner faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "from typing import List\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Concatenate,\n",
    "    Dense,\n",
    "    Embedding,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    Multiply,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import keras_tuner\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker('pl_PL')\n",
    "\n",
    "movielens_small_dataset = \"../ML/ml-latest-small\"\n",
    "start_date = pd.to_datetime(\"2020-01-01\")\n",
    "end_date = pd.to_datetime(\"2024-12-31\")\n",
    "\n",
    "def ffake(f, len, id=False):\n",
    "  if id: return [i for i in range(len)]\n",
    "  return [f().replace(\"\\n\", \" \") for _ in range(len)]\n",
    "\n",
    "def fake_users(project_name, len):\n",
    "  users = pd.DataFrame()\n",
    "  \n",
    "  users[\"id\"] = ffake(None, len, id=True)\n",
    "  users[\"name\"] = ffake(fake.first_name, len)\n",
    "  users[\"surname\"] = ffake(fake.last_name, len)\n",
    "  users[\"pesel\"] = ffake(fake.ssn, len)\n",
    "  users[\"adress\"] = ffake(fake.address, len)\n",
    "  users[\"email\"] = ffake(fake.email, len)\n",
    "  users[\"phone\"] = ffake(fake.phone_number, len)\n",
    "  \n",
    "  users.to_csv(f\"../app/saves/{project_name}/users.csv\", index=False, header=False)\n",
    "\n",
    "def prepare_save_from_movielens(project_name, limit): #610\n",
    "  if not os.path.exists(f\"../app/saves/{project_name}\"): os.makedirs(f\"../app/saves/{project_name}\")\n",
    "  \n",
    "  borrowed_books = pd.read_csv(f\"{movielens_small_dataset}/ratings.csv\", sep=\",\", names=[\"user_id\", \"book_id\", \"rating\", \" \"], usecols=[0, 1])\n",
    "  borrowed_books[\"borrow_date\"] = start_date + pd.to_timedelta(np.random.randint(0, (end_date - start_date).days, size=len(borrowed_books)), unit=\"D\")\n",
    "  borrowed_books[\"return_date\"] = borrowed_books[\"borrow_date\"] + pd.to_timedelta(np.random.randint(1, 31, size=len(borrowed_books)), unit=\"D\")\n",
    "  \n",
    "  books = pd.read_csv(f\"{movielens_small_dataset}/movies.csv\", sep=\",\", names=[\"book_id\", \"title\", \"tags\"],usecols=[0, 1])\n",
    "  filtered_borrowed_books = borrowed_books[borrowed_books[\"user_id\"] < limit]\n",
    "  books[\"title\"] = books[\"title\"].str.replace('\"', '', regex=False) \n",
    "  books[\"title\"] = books[\"title\"].str.replace(',', '', regex=False) \n",
    "  books[\"author\"] = [f\"{fake.first_name()} {fake.last_name()}\" for _ in range(len(books))]\n",
    "\n",
    "  books[\"isbn\"] = np.random.randint(4000000000000, 9999999999999, size=len(books))\n",
    "  books[\"year\"] = np.random.randint(1970, 2020, size=len(books))\n",
    "  books[\"available\"] = np.ones(shape=(len(books),))\n",
    "  if limit:\n",
    "    borrowed_books = borrowed_books[borrowed_books[\"user_id\"]<limit]\n",
    "    books = books[books[\"book_id\"].isin(filtered_borrowed_books[\"book_id\"])]\n",
    "  \n",
    "  borrowed_books.to_csv(f\"../app/saves/{project_name}/borrowed_books.csv\", index=False, header=False)\n",
    "  books.to_csv(f\"../app/saves/{project_name}/books.csv\", index=False, header=False)\n",
    "  \n",
    "  fake_users(project_name, len(np.unique(borrowed_books[\"user_id\"])))\n",
    "  \n",
    "prepare_save_from_movielens(\"MovieLens_s_dataset_FULL\", False)\n",
    "prepare_save_from_movielens(\"MovieLens_s_dataset_50\", 50)\n",
    "prepare_save_from_movielens(\"MovieLens_s_dataset_200\", 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/Workspace/c_project/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 22 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>interaction</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>277</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>314</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>257</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>510</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>1938</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item_id  user_id  interaction  predictions\n",
       "239       277     20.0          0.0     0.517737\n",
       "273       314     20.0          0.0     0.500988\n",
       "221       257     20.0          0.0     0.460191\n",
       "445       510     20.0          0.0     0.416102\n",
       "1416     1938     20.0          0.0     0.406503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RETURN:\n",
      "277 314 257 510 1938\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from ML.simple_model.make_tf_dataset import make_tf_dataset\n",
    "\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "books = pd.read_csv(f\"{movielens_small_dataset}/movies.csv\", sep=\",\", names=[\"item_id\", \" \", \"1\"], usecols=[0])\n",
    "def pred(args):\n",
    "  user_id = args[0]\n",
    "  items = np.array(args[1:])\n",
    "  savesFolder = f\".\"\n",
    "  model = load_model(f\"{savesFolder}/model.keras\")\n",
    "\n",
    "  data = pd.DataFrame({\n",
    "    \"user_id\": np.full(len(items), user_id),\n",
    "    \"item_id\": items,\n",
    "    \"interaction\": np.ones(shape=(len(args)-1,))\n",
    "  })\n",
    "  data = pd.merge(books, data, on=\"item_id\", how=\"outer\")\n",
    "  data['user_id'] = data['user_id'].fillna(user_id)\n",
    "  data['interaction'] = data['interaction'].fillna(0)\n",
    "\n",
    "  dataset, _ = make_tf_dataset(data, [\"interaction\"], val_split=0, seed=None)\n",
    "  \n",
    "  data[\"predictions\"] = model.predict(dataset) \n",
    "  data = data[data[\"interaction\"]==0].sort_values(\"predictions\", ascending=False)[:5]\n",
    "  \n",
    "  print(\"RETURN:\")\n",
    "  print(\" \".join(map(str, data[\"item_id\"].values)))\n",
    "\n",
    "limit=2\n",
    "pred(np.concatenate([[20],np.unique(books[\"item_id\"])[:limit]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
